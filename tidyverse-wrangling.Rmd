---
title: "Tidyverse - data wrangling"
author: "Advanced R"
date: "Thursday May 3, 2018"
output: html_document
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```


# Learning goal

Efficient data manipulation and transformation in the tidyverse.


```{r, warning=FALSE, message=FALSE}
load("adv-R-twin.RData")
```


# Example datasets

Liu et al., Quantitative variability of 342 plasma proteins in a human twin population, *Molecular Systems Biology*, 2015. [PMID: 25652787]

* The dataset contains 232 MS runs of plasma samples:
    - 58 pairs of monozygotic (MZ) and dizygotic (DZ) twins.
    - 2 time points.
    - $58 \times 2 \times 2 = 232$.

* Data were acquired with MS workflows of:
    - Data independent acquisition (DIA).
    - Selected reaction monitoring (SRM).

* We will use a subset of the original dataset (with `r length(unique(twin_dia$protein))` proteins by DIA and `r length(unique(twin_srm$protein))` proteins by SRM).

```{r}
str(twin_dia)
```

The two data frames have the same format, containing 9 columns:

* `protein` (chr): protein name.
* `feature` (chr): combination of peptide, precursor charge state, fragment ion, and product charge state, separated by `_`.
* `run` (chr): MS run identifier (R001-R232).
* `pair` (int): pair identifier number (1-58).
* `zygosity` (factor): zygosity (MZ, DZ).
* `subject` (int): subject identifier number (1-116).
* `visit` (int): time of visit (1, 2).
* `intensity_l` (num): integrated feature intensity from light (L) channel.
* `intensity_h` (num): integrated feature intensity from heavy (H, aka reference) channel.

```{r}
head(twin_dia)
head(twin_srm)
```


# Tasks for the case study

**Task 1:** normalization of feature intensities, in a way that the median intensity of each run in heavy channel is identical (constant normalization).

**Task 2:** comparison between DIA and SRM datasets, to evaluate their agreement in terms of protein quantification.

We will discuss tools in the **tidyverse** to address the tasks. In particular, how to tidy up messy datasets, manipulate and transform data, carry out split-apply-combine approach, and join datasets in a consistent fashion.


```{r}
library(tidyverse)
```

The [tidyverse](http://tidyverse.org/) is a collection of R packages that share common data representation and [design principles](http://tidyverse.tidyverse.org/articles/manifesto.html). It is designed to make data analysis easier. `library(tidyverse)` loads six core packages: ggplot2, tibble, tidyr, readr, purrr, and dplyr. These packages provide functions that are involved in most data analysis projects. We will introduce core functions in **tidyr** and **dplyr**, and touch on a few aspects of tibble, purrr and ggplot2. There are other packages in the tidyverse focusing on different aspects of data analysis that you may find useful. For example, stringr for strings, and broom for model objects that we will also discuss. 


# Helpful conventions for data wrangling

`as_tibble()` creates a **tibble** (`tbl_df`) from an existing data frame: 

```{r}
twin_dia <- as_tibble(twin_dia)
twin_srm <- as_tibble(twin_srm)
```

Tibbles are special data frames, which have an enhanced print method that shows the content nicely on the console: 

```{r}
class(twin_dia)
twin_dia
```

`View()` calls the data viewer in RStudio:

```{r, eval=FALSE}
View(twin_dia)
```

The **pipe operator** `%>%` to chain multiple operations: 

```{r, eval=FALSE}
# Equivalent representations
FUN(X, Y)
X %>% FUN(Y)
```

```{r, eval=FALSE}
# Chaining two operations
FUN_2( FUN_1(X, Y), Z )
X %>% FUN_1(Y) %>% FUN_2(Z)
```

When your operation involves a sequence of multiple function calls, this makes the action taken at each step and the whole analysis flow easier to understand. 

The RStudio keyboard shortcut: Ctrl + Shift + M (Windows), Cmd + Shift + M (Mac).


# Tidy data

In a tidy dataset:

* Each **variable** is saved in its own **column**.
* Each **observation** is saved in its own **row**.
* Each type of observational unit is stored in a single table.

Why tidy data? Tidy data complements R's **vectorized operations**. It is easy to access variables in a tidy dataset, and R will automatically preserve observations as you manipulate variables.

Are the datasets of the case study `twin_dia` and `twin_srm` tidy? Let's look at a few examples with values for 2 proteins (APOA, C1QA) and 3 samples (R001, R002, R003) from the SRM dataset.

```{r, echo=FALSE}
# Making untidy data
td_sub <- as_tibble(twin_srm) %>% select(protein, feature, run, intensity_h, intensity_l) %>% 
    filter(run %in% c("R001", "R002", "R003"), protein %in% c("APOA", "C1QA"))

sub1a <- td_sub %>% select(-intensity_l) %>% spread(run, intensity_h, convert = F)
sub1b <- td_sub %>% select(-intensity_h) %>% spread(run, intensity_l, convert = F)
sub2 <- td_sub %>% gather(key = "label", value = "intensity", intensity_h, intensity_l) %>% 
    mutate(label = ifelse(label == "intensity_h", "heavy", "light")) %>% 
    arrange(protein, feature, run, label)
sub12 <- sub2 %>% spread(key = run, value = intensity)
sub3 <- td_sub %>% unite(intensity_both, intensity_h, intensity_l, sep = "/")
```


```{r}
# Subset for heavy channel
sub1a
# Subset for light channel
sub1b
```

In `sub1a` and `sub1b`, some of the column names (R001, R002, R003) are values of a variable, rather than variables.

```{r}
sub2
```

As for `sub2`, people may have different opinions on whether it is tidy, based on the basic unit to be processed: 

* It is tidy, if you view *a feature in a channel (light or heavy) in one run* as an observation.

* It is not tidy, if you view *a feature in one run* as an observation, which is scattered across two rows.

We'll take the second view.

```{r}
sub12
```

`sub12` is a case with both issues.

```{r}
sub3
```

The `intensity_both` column in `sub3` contains both `intensity_h` and `intensity_l` variables, and values are saved as strings.

# tidyr

A package that helps reshape the layout of tabular datasets.

* Gather multiple columns into a key-value pair with `tidyr::gather()`.
* Spread a key-value pair into multiple columns with `tidyr::spread()`.
* Split and merge columns with `tidyr::unite()` and `tidyr::separate()`.


## Use `gather()` to gather multiple columns into a key-value pair

`gather()` moves column names into a **key** column, gathering the column values into a single **value** column.

```{r}
sub1a
```

To tidy this dataset, we need to gather the **value**s of feature intensities (in columns `R001`, `R002`, and `R003`) into a single variable `intensity_h`, and create a new variable `run`, a **key** relating the feature to its originating run:

```{r}
# gather(sub1a, key = run, value = intensity_h, R001, R002, R003)
sub1a %>% gather(key = run, value = intensity_h, R001, R002, R003)
```

Apply for both `sub1a` and `sub1b` and merge the results: 

```{r}
tidy1a <- sub1a %>% gather(key = run, value = intensity_h, R001, R002, R003)
tidy1b <- sub1b %>% gather(key = run, value = intensity_l, R001, R002, R003)
dplyr::left_join(tidy1a, tidy1b)  # merge two parts of the dataset, introduced later 
```


## Use `spread()` to spread a key-value pair into multiple columns

`spread()` moves the unique values of a **key** column into the column names, spreading the values of a
**value** column across the new columns that result.

```{r}
sub2
```

To tidy this dataset, we need to spread the values of the `intensity` column, into multiple columns named with the unique values of `label` column: 

```{r}
# spread(sub2, key = label, value = intensity)
sub2 %>% spread(key = label, value = intensity)
```

In some cases, both `gather()` and `spread()` are needed for data tidying.

```{r}
sub12
```

```{r}
sub12 %>% gather(run, intensity, R001, R002, R003)
sub12 %>% 
    gather(run, intensity, R001, R002, R003) %>% 
    spread(key = label, value = intensity) %>% 
    dplyr::rename(intensity_h = heavy, intensity_l = light)
```


## Use `separate()` to split a column by a string separator

```{r}
sub3 %>% separate(col = intensity_both, into = c("intensity_h", "intensity_l"), sep = "/")
```

Try to convert to better types using `convert = TRUE`, as in 

```{r, eval=FALSE}
sub3 %>% separate(col = intensity_both, into = c("intensity_h", "intensity_l"), sep = "/", convert = TRUE)
```

Separate `intensity_both` and `feature` columns:

```{r}
sub3 %>% 
    separate(col = intensity_both, into = c("intensity_h", "intensity_l"), sep = "/", convert = TRUE) %>%
    separate(col = feature, into = c("peptide", "z1", "fragment", "z3"), sep = "_")
```


## Use `unite()` to merge columns into a single column

```{r}
sub3 %>% 
    separate(col = intensity_both, into = c("intensity_h", "intensity_l"), sep = "/", convert = TRUE) %>%
    separate(col = feature, into = c("peptide", "z1", "fragment", "z3"), sep = "_") %>% 
    unite(col = transition, z1, fragment, z3, sep = "_")
```


# dplyr

A package that helps manipulate and transform tabular data. 

* Reshape a dataset (without changing its content):
    - Rename the columns of a data frame with `dplyr::rename()`.
    - Order rows by values of columns with `dplyr::arrange()`.

* Data manipulation and transformation for a single dataset:
    - Extract existing variables with `dplyr::select()`.
    - Extract existing observations with `dplyr::filter()`.
    - Add new variables with `dplyr::mutate()`.
    - Make grouped summaries with `dplyr::summarise()` and `dplyr::group_by()`.

* Join datasets:
    - Mutating joins with `dplyr::left_join()`, `dplyr::right_join()`, `dplyr::inner_join()`, `dplyr::full_join()`.
    - Filtering joins `dplyr::semi_join()`, `dplyr::anti_join()`.


## Use `rename()` to rename columns

```{r}
# Rename column intensity_h as inty_H, intensity_l as inty_L
twin_dia %>% rename(inty_H = intensity_h, inty_L = intensity_l)
```


## Use `arrange()` to order rows 

```{r}
# Order rows by values of columns protein, run, and feature
twin_dia %>% arrange(protein, run, feature)

# Order rows by values of column subject, from high to low
twin_dia %>% arrange(desc(subject))
```


## Use `select()` to extract existing variables

```{r}
# Select columns protein and feature
twin_dia %>% select(protein, feature)

# Exclude column pair
twin_dia %>% select(-pair)

# Select from column feature to column intensity_h
twin_dia %>% select(feature:intensity_h)
```

This is helpful to obtain unique values for particular variables, for example: 

```{r}
twin_dia %>% 
    select(protein, feature) %>% 
    distinct()
```

```{r, eval=FALSE}
# Same as
twin_dia %>% distinct(protein, feature)
```


## Use `filter()` to extract existing observations

We select only the last four columns to print the result:

```{r}
twin_dia %>% filter(!is.na(intensity_h)) %>% 
    select(subject:intensity_l)

# Comma as AND operation
twin_dia %>% filter(is.na(intensity_h), !is.na(intensity_l)) %>% 
    select(subject:intensity_l)
```


## Use `mutate()` to add new variables

`mutate()` uses **window functions**, functions that take a vector of values and return another vector of values.

```{r}
# Log2 transformation
twin_dia %>% mutate(log2inty_l = log2(intensity_l))

# Use the just generated variables
twin_dia %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l), 
        log2inty_d = log2inty_l - log2inty_h
    )
```


## Use `group_by()` and `summarise()` to make grouped summaries

* `summarise()` uses **summary functions**, functions that take a vector of values and return a single value.

* `group_by()` defines the unit of analysis by adding grouping information that can be recognized by `summarise()`. 

```{r}
# Compute mean, sd and median of values in column intensity_l
twin_dia %>% 
    summarise(
        intensity_ave = mean(intensity_l, na.rm = TRUE), 
        intensity_sd = sd(intensity_l, na.rm = TRUE), 
        intensity_med = median(intensity_l, na.rm = TRUE)
    )
```

```{r}
# Compute mean, sd and median of values in column intensity_l, within each run
twin_dia %>% 
    group_by(run) %>% 
    summarise(
        intensity_ave = mean(intensity_l, na.rm = TRUE), 
        intensity_sd = sd(intensity_l, na.rm = TRUE), 
        intensity_med = median(intensity_l, na.rm = TRUE)
    )
```

`group_by()` + `summarise()` serve as a powerful tool for the split-apply-combine approach. To compute the quantities for constant normalization:

```{r}
# Equalizing medians
twin_dia %>% mutate(log2inty_h = log2(intensity_h)) %>% 
    group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)
```

To address Task 1, we will then need to merge this summary back to the original data frame.


# Merge datasets

All the figures in this section are from [R for Data Science](http://r4ds.had.co.nz/) by Hadley Wickham and Garrett Grolemund.

Consider two datasets `x` and `y`: 

```{r}
x <- tibble(
    key = c(1, 2, 3), 
    val_x = c("x1", "x2", "x3")
)

y <- tibble(
    key = c(1, 2, 4), 
    val_y = c("y1", "y2", "y3")
)
```

```{r, out.width=200, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-setup.png")
```


## Mutating joins


### Inner join 

`inner_join(x, y)`: keep only the observations with equal keys.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-inner.png")
```

### Outer joins 

* `left_join(x, y)`: keep all observations in `x` and merge `y` to it.

* `right_join(x, y)`: keep all observations in `y` and merge `x` to it.

* `full_join(x, y)`: keep all observations in `x` and `y`.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-outer.png")
```


## Filtering joins

* `semi_join(x, y)`: keep all observations in `x` that have a match in `y`.

* `anti_join(x, y)`: drops all observations in `x` that have a match in `y`.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-semi.png")
```

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-anti.png")
```


# Task 1: constant normalization


## Use `summarise()` and `group_by()` to compute the run-level adjustment

```{r}
twin_dia <- twin_dia %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l)
    )

med_dia <- twin_dia %>% 
    group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)

med_dia
```


## Merge the adjustment back to the original dataset

```{r}
left_join(twin_dia, med_dia)
```

```{r}
twin_dia2 <- left_join(twin_dia, med_dia) %>% 
    mutate(
        log2inty_h = log2inty_h + log2inty_adj, 
        log2inty_l = log2inty_l + log2inty_adj, 
        intensity_h = 2 ^ log2inty_h,
        intensity_l = 2 ^ log2inty_l
    )
```

Similarly, for the SRM dataset:

```{r}
twin_srm <- twin_srm %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l)
    ) 

med_srm <- twin_srm %>% group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)

twin_srm2 <- left_join(twin_srm, med_srm) %>% 
    mutate(
        log2inty_h = log2inty_h + log2inty_adj, 
        log2inty_l = log2inty_l + log2inty_adj, 
        intensity_h = 2 ^ log2inty_h,
        intensity_l = 2 ^ log2inty_l
    )
```


## Visualize the result

Boxplot of feature log-intensities in each run, before normalization:

```{r, fig.width=6, fig.height=4, fig.align='center', warning=FALSE, message=FALSE}
twin_dia %>% filter(grepl(paste(sprintf("%03d", 1:20), collapse = "|"), run)) %>% 
    ggplot(aes(run, log2inty_h)) + 
    geom_boxplot() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Boxplot of feature log-intensities in each run, after normalization:

```{r, fig.width=6, fig.height=4, fig.align='center', warning=FALSE, message=FALSE}
twin_dia2 %>% filter(grepl(paste(sprintf("%03d", 1:20), collapse = "|"), run)) %>% 
    ggplot(aes(run, log2inty_h)) + 
    geom_boxplot() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


# Task 2: comparison between DIA and SRM datasets

Evaluate the agreement of protein quantification between DIA and SRM:

* Summarize protein abundance with the **log of sum** of feature intensities in both datasets.

* Merge the summarized values from the two datasets.

* Evaluate their agreement.


## Summarization in each dataset

Sum up all the normalized feature intensities (in the light channel) for each protein:

```{r}
# Perform log of sum in the DIA dataset
los_dia <- twin_dia2 %>% group_by(run, protein) %>% 
    summarise(sum_dia = sum(intensity_l, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(logsum_dia = ifelse(sum_dia == 0, 0, log2(sum_dia)))
los_dia
```

```{r}
# Summarization for the SRM data
los_srm <- twin_srm2 %>% group_by(run, protein) %>% 
    summarise(sum_srm = sum(intensity_l, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(logsum_srm = ifelse(sum_srm == 0, 0, log2(sum_srm)))
```


## Merge two datasets

```{r}
# Merge results (with proteins quantified in both)
los_all <- inner_join(los_dia, los_srm)
```

```{r, fig.width=5, fig.height=5, fig.align='center'}
ggplot(los_all, aes(logsum_dia, logsum_srm)) + 
    geom_point() + geom_smooth(se = FALSE, method = "lm")
```

```{r, fig.width=7.5, fig.height=5, fig.align='center'}
ggplot(los_all, aes(logsum_dia, logsum_srm)) + 
    geom_point(aes(colour = protein))
```


## Evaluate the agreement

Compute the correlation coefficient:

```{r}
cor(los_all$logsum_dia, los_all$logsum_srm)
```

Compute the correlation per protein:

```{r}
los_all %>% group_by(protein) %>% 
    summarise(correlation = cor(logsum_dia, logsum_srm))
```


# Apply arbitrary operations to grouped data

The approach with `summarise()` + `group_by()` is limited to the use of **summary functions** that takes a vector of values of returns a summarized value. To work with arbitrary operations, more general tools are required. 

```{r}
cor.test(los_all$logsum_dia, los_all$logsum_srm)
```

```{r, eval=F}
# This would fail... 
los_all %>% group_by(protein) %>% 
    summarise(corres = cor.test(logsum_dia, logsum_srm))
```

One way to address this issue is to pass on arbitrary operations to `dplyr::do()`. Note that this approach is slightly out of date, and you may find the **map functions** to be discussed in the next section are more intuitive and easier to work with **list-columns**. 


## `group_by()` + `do()`

Here the operation `head()` returns multiple rows:

```{r}
twin_dia2 %>% 
    group_by(protein) %>% 
    do(head(., 2))
```

The pronoun `.` is used as an argument placeholder, referring to the group data to be processed. 

If you use a named argument inside `do()`, it creates a **list-column** in the output:

```{r}
twin_dia2 %>% 
    group_by(protein) %>% 
    do(top2 = head(., 2))
```

The list-column is useful to store arbitrary R objects, such as models.

```{r}
los_all %>% group_by(protein) %>% 
    do(fit_cor = cor.test(.$logsum_dia, .$logsum_srm))
```

We can use double brackets `[[]]` to retrieve the model objects from the list-column `fit_cor`:

```{r}
los_cor <- los_all %>% group_by(protein) %>% 
    do(fit_cor = cor.test(.$logsum_dia, .$logsum_srm))
los_cor$fit_cor[[1]]
```

In the next section, we will learn more techniques to work with list-columns and to develop general workflows for both data wrangling and statistical modeling.


# Resources

* R for Data Science, Hadley Wickham and Garrett Grolemund
    + http://r4ds.had.co.nz/transform.html
    + http://r4ds.had.co.nz/tibbles.html
    + http://r4ds.had.co.nz/tidy-data.html
    + http://r4ds.had.co.nz/relational-data.html

* RStudio Cheat Sheets: 
    + https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/data-import-cheatsheet.pdf
    + https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/data-transformation-cheatsheet.pdf

