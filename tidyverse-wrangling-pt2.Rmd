---
title: "Tidyverse: data wrangling (part 2)"
author: "Advanced R"
date: "Thursday May 3, 2018"
output: html_document
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```


## Tasks

* **Task 1:** normalize feature intensities, in a way that the median of reference feature intensities of each run is identical.
* **Task 2:** evaluate the agreement between the DIA and SRM datasets in terms of protein quantification.


## tidyr recap

A package that helps reshape the layout of tabular datasets.

* Gather multiple columns into a key-value pair with `tidyr::gather()`.
* Spread a key-value pair into multiple columns with `tidyr::spread()`.
* Split and merge columns with `tidyr::separate()` and `tidyr::unite()`.


## dplyr recap

A package that helps manipulate and transform tabular data. 

* Reshape a dataset (without changing its content):
    - Rename the columns of a data frame with `dplyr::rename()`.
    - Order rows by values of columns with `dplyr::arrange()`.

* Data manipulation and transformation for a single dataset:
    - Extract existing variables with `dplyr::select()`.
    - Extract existing observations with `dplyr::filter()`.
    - Add new variables with `dplyr::mutate()`.
    - Make grouped summaries with `dplyr::summarise()` and `dplyr::group_by()`.

* Join datasets:
    - Mutating joins with `dplyr::left_join()`, `dplyr::right_join()`, `dplyr::inner_join()`, `dplyr::full_join()`.
    - Filtering joins `dplyr::semi_join()`, `dplyr::anti_join()`.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
load("adv-R-twin.RData")

twin_dia <- as_tibble(twin_dia)
twin_srm <- as_tibble(twin_srm)
```

We've learned how to compute the quantities for median adjusted normalization with `group_by()` + `summarise()`:

```{r}
# Equalizing medians
twin_dia %>% mutate(log2inty_h = log2(intensity_h)) %>% 
    group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)
```

We need to merge this summary back to the original data frame.


## Join datasets

* **Mutating joins** use information from one dataset to **add variables** to another dataset

* **Filtering joins** use information from one dataset to **extract cases** from another dataset

Example figures in this section are from [R for Data Science](http://r4ds.had.co.nz/) by Hadley Wickham and Garrett Grolemund. Consider two datasets `x` and `y`: 

```{r}
x <- tibble(
    key = c(1, 2, 3), 
    val_x = c("x1", "x2", "x3")
)

y <- tibble(
    key = c(1, 2, 4), 
    val_y = c("y1", "y2", "y3")
)
```

```{r, out.width=200, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-setup.png")
```


### Mutating joins


#### Inner join 

* `inner_join(x, y)`: keep only the observations with equal keys.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-inner.png")
```

#### Outer joins 

* `left_join(x, y)`: keep all observations in `x` and merge `y` to it.
* `right_join(x, y)`: keep all observations in `y` and merge `x` to it.
* `full_join(x, y)`: keep all observations in `x` and `y`.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-outer.png")
```


### Filtering joins

* `semi_join(x, y)`: keep all observations in `x` that have a match in `y`.
* `anti_join(x, y)`: drops all observations in `x` that have a match in `y`.

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-semi.png")
```

```{r, out.width=500, echo=FALSE, fig.align='center'}
knitr::include_graphics("http://r4ds.had.co.nz/diagrams/join-anti.png")
```


## Task 1: median adjusted normalization


### Use `summarise()` and `group_by()` to compute the run-level adjustment

```{r}
twin_dia <- twin_dia %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l)
    )

med_dia <- twin_dia %>% 
    group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)

med_dia
```


### Merge the adjustment back to the original dataset

```{r}
left_join(twin_dia, med_dia)
```

```{r}
twin_dia2 <- left_join(twin_dia, med_dia) %>% 
    mutate(
        log2inty_h = log2inty_h + log2inty_adj, 
        log2inty_l = log2inty_l + log2inty_adj, 
        intensity_h = 2 ^ log2inty_h,
        intensity_l = 2 ^ log2inty_l
    )
```

Similarly, for the SRM dataset:

```{r}
twin_srm <- twin_srm %>% 
    mutate(
        log2inty_h = log2(intensity_h), 
        log2inty_l = log2(intensity_l)
    ) 

med_srm <- twin_srm %>% group_by(run) %>% 
    summarise(log2inty_med = median(log2inty_h, na.rm = TRUE)) %>% 
    mutate(log2inty_adj = median(log2inty_med) - log2inty_med)

twin_srm2 <- left_join(twin_srm, med_srm) %>% 
    mutate(
        log2inty_h = log2inty_h + log2inty_adj, 
        log2inty_l = log2inty_l + log2inty_adj, 
        intensity_h = 2 ^ log2inty_h,
        intensity_l = 2 ^ log2inty_l
    )
```


### Visualize the result

Boxplot of feature log-intensities in each run, before normalization:

```{r, fig.width=6, fig.height=4, fig.align='center', warning=FALSE, message=FALSE}
twin_dia %>% filter(grepl(paste(sprintf("%03d", 1:20), collapse = "|"), run)) %>% 
    ggplot(aes(run, log2inty_h)) + 
    geom_boxplot() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Boxplot of feature log-intensities in each run, after normalization:

```{r, fig.width=6, fig.height=4, fig.align='center', warning=FALSE, message=FALSE}
twin_dia2 %>% filter(grepl(paste(sprintf("%03d", 1:20), collapse = "|"), run)) %>% 
    ggplot(aes(run, log2inty_h)) + 
    geom_boxplot() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


## Task 2: comparison between DIA and SRM datasets

Evaluate the agreement of protein quantification between DIA and SRM:

* Summarize protein abundance with the **log of sum** of feature intensities in both datasets.

* Merge the summarized values from the two datasets.

* Evaluate their agreement.


### Summarization in each dataset

Sum up all the normalized feature intensities (in the light channel) for each protein:

```{r}
# Perform log of sum in the DIA dataset
los_dia <- twin_dia2 %>% group_by(run, protein) %>% 
    summarise(sum_dia = sum(intensity_l, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(logsum_dia = ifelse(sum_dia == 0, 0, log2(sum_dia)))
los_dia
```

```{r}
# Summarization for the SRM data
los_srm <- twin_srm2 %>% group_by(run, protein) %>% 
    summarise(sum_srm = sum(intensity_l, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(logsum_srm = ifelse(sum_srm == 0, 0, log2(sum_srm)))
```


### Merge two datasets

```{r}
# Merge results (with proteins quantified in both)
los_all <- inner_join(los_dia, los_srm)
```

```{r, fig.width=5, fig.height=5, fig.align='center'}
ggplot(los_all, aes(logsum_dia, logsum_srm)) + 
    geom_point() + 
    geom_smooth(se = FALSE, method = "lm")
```

```{r, fig.width=7.5, fig.height=5, fig.align='center'}
ggplot(los_all, aes(logsum_dia, logsum_srm)) + 
    geom_point(aes(colour = protein))
```


### Evaluate the agreement

Compute the correlation coefficient:

```{r}
cor(los_all$logsum_dia, los_all$logsum_srm)
```

Compute the correlation per protein:

```{r}
los_all %>% group_by(protein) %>% 
    summarise(correlation = cor(logsum_dia, logsum_srm))
```


## Edge of the `summarise()` + `group_by()` approach

The approach with `summarise()` + `group_by()` is limited to the use of **summary functions** that takes a vector of values of returns a summarized value. 


### Summaries that are not a single number

```{r, eval=F}
twin_dia %>% 
    group_by(run) %>% 
    summarise(log2inty_quant = quantile(log2inty_h, c(0.25, 0.5, 0.75), na.rm = TRUE))
```

### Apply arbitrary operations to grouped data

To work with arbitrary operations, more general tools are required. 

```{r}
cor.test(los_all$logsum_dia, los_all$logsum_srm)
```

```{r, eval=F}
# This would fail... 
los_all %>% 
    group_by(protein) %>% 
    summarise(fit_cor = cor.test(logsum_dia, logsum_srm))
```


### List-columns

Wrap around the operation with a `list()`

```{r}
twin_dia %>% 
    group_by(run) %>% 
    summarise(log2inty_quant = list(quantile(log2inty_h, c(0.25, 0.5, 0.75), na.rm = TRUE)))
```

The list-column is useful to store arbitrary R objects, such as models.

```{r}
los_all %>% 
    group_by(protein) %>% 
    summarise(fit_cor = list(cor.test(logsum_dia, logsum_srm)))
```

We can use double brackets `[[]]` to retrieve the model objects from the list-column `fit_cor`:

```{r}
los_cor <- los_all %>% 
    group_by(protein) %>% 
    summarise(fit_cor = list(cor.test(logsum_dia, logsum_srm)))
los_cor$fit_cor[[1]]
```

In the next section, we will learn more techniques to work with **list-columns** and to develop general workflows for both data wrangling and statistical modeling.


## Resources

* R for Data Science, Hadley Wickham and Garrett Grolemund
    + http://r4ds.had.co.nz/transform.html
    + http://r4ds.had.co.nz/tibbles.html
    + http://r4ds.had.co.nz/tidy-data.html
    + http://r4ds.had.co.nz/relational-data.html

* Data Science in the tidyverse
    + https://github.com/hadley/data-science-in-tidyverse/

* RStudio Cheat Sheets: 
    + https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/data-import-cheatsheet.pdf
    + https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/data-transformation-cheatsheet.pdf

